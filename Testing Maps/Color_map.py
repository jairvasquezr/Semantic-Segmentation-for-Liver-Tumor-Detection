{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1qaN0gQIckIRvNA9LjSt84D7LaPFhTVBH","authorship_tag":"ABX9TyMgM48T8kxS6f0w729/W+Za"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from PIL import Image\n","from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n","\n","def load_image(path):\n","    \"\"\"Carga una imagen y la convierte a RGB.\"\"\"\n","    return Image.open(path).convert(\"RGB\")\n","\n","def predict_image(model, feature_extractor, image_path, target_size=(512, 512)):\n","    \"\"\"\n","    Realiza la predicción de segmentación sobre una imagen y ajusta la resolución de salida.\n","\n","    Args:\n","        model: Modelo Segformer entrenado.\n","        feature_extractor: Preprocesador de imagen.\n","        image_path: Ruta a la imagen de testing.\n","        target_size: Tamaño final deseado para la máscara de salida.\n","\n","    Returns:\n","        Predicción en forma de máscara con índices de clase (0: background, 1: liver, 2: tumor).\n","    \"\"\"\n","    image = load_image(image_path)\n","    encoding = feature_extractor(images=np.array(image), return_tensors=\"pt\")\n","    pixel_values = encoding[\"pixel_values\"]\n","\n","    with torch.no_grad():\n","        outputs = model(pixel_values)\n","\n","    logits = outputs.logits  # Shape: [batch_size, num_labels, H, W]\n","\n","    # Interpolación de logits a 512x512 antes de aplicar argmax\n","    logits_up = F.interpolate(logits, size=target_size, mode=\"bilinear\", align_corners=False)\n","    predicted_mask = torch.argmax(logits_up, dim=1).squeeze(0).cpu().numpy()\n","\n","    return predicted_mask\n","\n","def apply_color_map(mask):\n","    \"\"\"\n","    Aplica un mapa de colores a la máscara de segmentación.\n","\n","    Mapeo:\n","      - 0: background -> negro [0, 0, 0]\n","      - 1: liver -> verde [0, 255, 0]\n","      - 2: tumor -> rojo [255, 0, 0]\n","\n","    Args:\n","        mask: Array 2D con índices de clase.\n","\n","    Returns:\n","        Imagen de la máscara coloreada (array 3D en formato uint8).\n","    \"\"\"\n","    color_map = np.array([\n","        [0, 0, 0],      # 0: Background (negro)\n","        [0, 255, 0],    # 1: Liver (verde)\n","        [255, 0, 0]     # 2: Tumor (rojo)\n","    ], dtype=np.uint8)\n","\n","    colored_mask = color_map[mask]\n","    return colored_mask\n","\n","def main():\n","    # Actualiza estas rutas según tu entorno en Compute Canada\n","    model_save_path = \"/content/drive/MyDrive/ELAP_Project/models/test_1.0/model_test_1.0\"  # Ruta del modelo entrenado\n","    test_img_dir = \"/content/drive/MyDrive/testing/imagesTs\"  # Directorio de imágenes de testing en PNG\n","    output_dir = \"/content/drive/MyDrive/testing/results_color_map\"  # Directorio para guardar las predicciones\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Cargar el modelo y el feature extractor\n","    feature_extractor = SegformerImageProcessor.from_pretrained(model_save_path)\n","    model = SegformerForSemanticSegmentation.from_pretrained(model_save_path)\n","    model.eval()  # Modo evaluación\n","\n","    # Listar imágenes de testing (se asume extensión .png)\n","    test_images = [f for f in os.listdir(test_img_dir) if f.lower().endswith(\".png\")]\n","    print(f\"Se encontraron {len(test_images)} imágenes de testing.\")\n","\n","    # Procesar cada imagen y guardar la máscara coloreada sin necesidad de redimensionamiento extra\n","    for img_name in test_images:\n","        img_path = os.path.join(test_img_dir, img_name)\n","        pred_mask = predict_image(model, feature_extractor, img_path)\n","        colored_mask = apply_color_map(pred_mask)\n","\n","        # Guardar la imagen con la resolución correcta (512x512)\n","        output_path = os.path.join(output_dir, f\"pred_{img_name}\")\n","        Image.fromarray(colored_mask).save(output_path)\n","        print(f\"Procesada {img_name} -> {output_path}\")\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl9YNSWGkyOx","executionInfo":{"status":"ok","timestamp":1743791813364,"user_tz":240,"elapsed":58030,"user":{"displayName":"Jair Ramos","userId":"08406808744877036134"}},"outputId":"e134bff4-02fa-4455-9c8d-13339dd56b49"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Se encontraron 8 imágenes de testing.\n","Procesada Copy of liver_129_slice242.png -> /content/drive/MyDrive/testing/results_color_map/pred_Copy of liver_129_slice242.png\n","Procesada Copy of liver_95_slice545.png -> /content/drive/MyDrive/testing/results_color_map/pred_Copy of liver_95_slice545.png\n","Procesada Copy of liver_24_slice240.png -> /content/drive/MyDrive/testing/results_color_map/pred_Copy of liver_24_slice240.png\n","Procesada Copy of liver_28_slice75.png -> /content/drive/MyDrive/testing/results_color_map/pred_Copy of liver_28_slice75.png\n","Procesada liver_101_slice387.png -> /content/drive/MyDrive/testing/results_color_map/pred_liver_101_slice387.png\n","Procesada liver_81_slice288 (1).png -> /content/drive/MyDrive/testing/results_color_map/pred_liver_81_slice288 (1).png\n","Procesada aug_20_liver_20_slice532.png -> /content/drive/MyDrive/testing/results_color_map/pred_aug_20_liver_20_slice532.png\n","Procesada liver_54_slice77 (2).png -> /content/drive/MyDrive/testing/results_color_map/pred_liver_54_slice77 (2).png\n"]}]}]}
